{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HumansNHorses.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO7cuMktXZUsIMDUmiPG0MW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"N6esROxSsb9f"},"outputs":[],"source":["#Building a CNN to to Distinguish Between Horses and Humans\n","import urllib.request\n","import zipfile\n","url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\"\n","file_name = \"horse-or-human.zip\"\n","training_dir = 'horse-or-human/training/'\n","urllib.request.urlretrieve(url , file_name)\n","zip_ref = zipfile.ZipFile(file_name , 'r')\n","zip_ref.extractall(training_dir)\n","zip_ref.close()"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","#All images will be rescaled by 1/255 \n","train_datagen = ImageDataGenerator(rescale = 1./255)\n","#Our image is 300X300 data and mode is set binary cause there are only two types of images if we have more than two types of images than we use categorical mode\n","train_generator = train_datagen.flow_from_directory(training_dir , target_size = (300 , 300), class_mode = 'binary')\n","\n","  \n","\n"],"metadata":{"id":"e-aJ3xbm4HsB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648366068969,"user_tz":-330,"elapsed":1550,"user":{"displayName":"Akash Sri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaoFus7F0z9qwzRSUzhtH_cS1fo_jYpgFmuJkZ=s64","userId":"07595179456817660778"}},"outputId":"56f6158a-3092-491d-acc9-d59e4ba53a3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1027 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","model = tf.keras.models.Sequential([\n","                tf.keras.layers.Conv2D(16 , (3,3) , activation='relu' , input_shape = (300 , 300 , 3)),\n","                tf.keras.layers.MaxPooling2D(2,2) , \n","                tf.keras.layers.Flatten() , \n","                tf.keras.layers.Dense(512 , activation = 'relu') , \n","                tf.keras.layers.Dense(1 , activation = 'relu') , \n","                \n","])\n","\n","model.compile(loss = 'binary_crossentropy' , optimizer = tf.keras.optimizers.RMSprop(lr = 0.001) , metrics = ['accuracy'])\n","history = model.fit_generator(train_generator , epochs = 15)"],"metadata":{"id":"ZLgk8lcSQF2V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648064925961,"user_tz":-330,"elapsed":1950894,"user":{"displayName":"Akash Sri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaoFus7F0z9qwzRSUzhtH_cS1fo_jYpgFmuJkZ=s64","userId":"07595179456817660778"}},"outputId":"80ee09be-32e9-4d5e-f101-1d546f3a20ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  if sys.path[0] == '':\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","33/33 [==============================] - 111s 3s/step - loss: 7.3991 - accuracy: 0.5141\n","Epoch 2/15\n","33/33 [==============================] - 103s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 3/15\n","33/33 [==============================] - 104s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 4/15\n","33/33 [==============================] - 103s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 5/15\n","33/33 [==============================] - 104s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 6/15\n","33/33 [==============================] - 105s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 7/15\n","33/33 [==============================] - 104s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 8/15\n","33/33 [==============================] - 104s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 9/15\n","33/33 [==============================] - 106s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 10/15\n","33/33 [==============================] - 111s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 11/15\n","33/33 [==============================] - 105s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 12/15\n","33/33 [==============================] - 106s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 13/15\n","33/33 [==============================] - 105s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 14/15\n","33/33 [==============================] - 105s 3s/step - loss: 7.4242 - accuracy: 0.5131\n","Epoch 15/15\n","33/33 [==============================] - 110s 3s/step - loss: 7.4242 - accuracy: 0.5131\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xD8O41_04Z83","executionInfo":{"status":"ok","timestamp":1648059045879,"user_tz":-330,"elapsed":642,"user":{"displayName":"Akash Sri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaoFus7F0z9qwzRSUzhtH_cS1fo_jYpgFmuJkZ=s64","userId":"07595179456817660778"}},"outputId":"c858e288-106b-45eb-a363-40318da0787c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_10 (Conv2D)          (None, 298, 298, 16)      448       \n","                                                                 \n"," max_pooling2d_10 (MaxPoolin  (None, 149, 149, 16)     0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 147, 147, 32)      4640      \n","                                                                 \n"," max_pooling2d_11 (MaxPoolin  (None, 73, 73, 32)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 71, 71, 64)        18496     \n","                                                                 \n"," max_pooling2d_12 (MaxPoolin  (None, 35, 35, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 33, 33, 64)        36928     \n","                                                                 \n"," max_pooling2d_13 (MaxPoolin  (None, 16, 16, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 14, 14, 64)        36928     \n","                                                                 \n"," max_pooling2d_14 (MaxPoolin  (None, 7, 7, 64)         0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_2 (Flatten)         (None, 3136)              0         \n","                                                                 \n"," dense_4 (Dense)             (None, 512)               1606144   \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 1,704,097\n","Trainable params: 1,704,097\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["validation_url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\"\n","validation_file_name = \"validation-horse-or-human.zip\"\n","validation_dir = 'horse-or-human/validation/'\n","urllib.request.urlretrieve(validation_url, validation_file_name)\n","zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n","zip_ref.extractall(validation_dir)\n","zip_ref.close()"],"metadata":{"id":"O7n0zuoS2NZF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Another image data generator to manage these images for validiation part\n","validation_datagen = ImageDataGenerator(rescale = 1./255) \n","validation_generator = train_datagen.flow_from_directory(validation_dir , target_size = (300 , 300) , class_mode = 'binary')\n","#here we are passing out validation_data \n","history = model.fit_generator(train_generator , epochs = 15 , validation_data = validation_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWYUvcBp2Xd2","executionInfo":{"status":"ok","timestamp":1648060849815,"user_tz":-330,"elapsed":1763967,"user":{"displayName":"Akash Sri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaoFus7F0z9qwzRSUzhtH_cS1fo_jYpgFmuJkZ=s64","userId":"07595179456817660778"}},"outputId":"31bf4c0a-a1bc-48df-8420-90607beb8355"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 256 images belonging to 2 classes.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  \"\"\"\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","33/33 [==============================] - 96s 3s/step - loss: 1.4620e-06 - accuracy: 1.0000 - val_loss: 4.8463 - val_accuracy: 0.8438\n","Epoch 2/15\n","33/33 [==============================] - 97s 3s/step - loss: 3.9629e-07 - accuracy: 1.0000 - val_loss: 4.4804 - val_accuracy: 0.8516\n","Epoch 3/15\n","33/33 [==============================] - 95s 3s/step - loss: 2.4500 - accuracy: 0.9786 - val_loss: 5.7186 - val_accuracy: 0.7969\n","Epoch 4/15\n","33/33 [==============================] - 94s 3s/step - loss: 6.0109e-05 - accuracy: 1.0000 - val_loss: 5.3612 - val_accuracy: 0.8164\n","Epoch 5/15\n","33/33 [==============================] - 94s 3s/step - loss: 2.7748e-05 - accuracy: 1.0000 - val_loss: 5.6112 - val_accuracy: 0.8125\n","Epoch 6/15\n","33/33 [==============================] - 95s 3s/step - loss: 8.2546e-06 - accuracy: 1.0000 - val_loss: 5.6305 - val_accuracy: 0.8242\n","Epoch 7/15\n","33/33 [==============================] - 96s 3s/step - loss: 2.2668e-06 - accuracy: 1.0000 - val_loss: 6.5576 - val_accuracy: 0.8203\n","Epoch 8/15\n","33/33 [==============================] - 95s 3s/step - loss: 3.6794e-07 - accuracy: 1.0000 - val_loss: 8.1736 - val_accuracy: 0.8164\n","Epoch 9/15\n","33/33 [==============================] - 94s 3s/step - loss: 2.2548e-08 - accuracy: 1.0000 - val_loss: 7.7675 - val_accuracy: 0.8242\n","Epoch 10/15\n","33/33 [==============================] - 94s 3s/step - loss: 0.1681 - accuracy: 0.9825 - val_loss: 2.5762 - val_accuracy: 0.8320\n","Epoch 11/15\n","33/33 [==============================] - 94s 3s/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 5.3259 - val_accuracy: 0.8398\n","Epoch 12/15\n","33/33 [==============================] - 94s 3s/step - loss: 0.0407 - accuracy: 0.9942 - val_loss: 4.3383 - val_accuracy: 0.8438\n","Epoch 13/15\n","33/33 [==============================] - 101s 3s/step - loss: 6.5417e-05 - accuracy: 1.0000 - val_loss: 4.3284 - val_accuracy: 0.8477\n","Epoch 14/15\n","33/33 [==============================] - 96s 3s/step - loss: 6.4654e-06 - accuracy: 1.0000 - val_loss: 4.6512 - val_accuracy: 0.8477\n","Epoch 15/15\n","33/33 [==============================] - 96s 3s/step - loss: 2.6435e-06 - accuracy: 1.0000 - val_loss: 4.9551 - val_accuracy: 0.8516\n"]}]},{"cell_type":"markdown","source":["**Loading a Pretrained model to work with Inception V3 to classify images**"],"metadata":{"id":"pIKcdO2aKEdk"}},{"cell_type":"code","source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","import urllib.request\n","weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n","weights_file = \"inception_v3.h5\"\n","urllib.request.urlretrieve(weights_url , weights_file)\n","pre_trained_model = InceptionV3(input_shape = (150,150,3) , include_top = False , weights = None)\n","pre_trained_model.load_weights(weights_file)\n","\n"],"metadata":{"id":"KAUbMd23KEEf"},"execution_count":null,"outputs":[]}]}